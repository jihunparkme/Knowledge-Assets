# eTc

<br>

## 함수 호출

### Call By Value

- 값에 의한 호출

- 변수의 값(메모리 공간에 저장된 값)을 복사해서 함수 호출
  - 함수 인자 전달에 사용되는 매개변수가 많아질 수 있음
    <img src="..\img\pointer20.png" alt="img" style="zoom: 120%;" />   값을 복사했으므로, a의 값이 변하지 않음



### Call By Reference

- 주소에 의한 호출

- 주소(메모리 공간의 주소)를 참조해서 함수 호출
  - 배열이나 구조체와 같은 데이터를 함수에 전달에 유용 (실행 시간 단축, 메모리 공간의 적은 차지)
    <img src="..\img\pointer21.png" alt="img" style="zoom: 130%;" />    주소를 사용하므로, a의 값이 변함

<br>

## Normal Distribution

- 정규분포
- 정규분포는 평균과 분산(표준편차)에 의해 모양이 결정

<br>

## Stack VS Queue

### Stack

- 먼저 들어간 자료가 나중에 나오는 자료구조 (후입선출)

- 자료를 넣는 push 함수와 자료를 빼는 pop 함수 (empty, full 등 ..)

- 시간 복잡도

  - push : O(1)
  - pop : O(1)

### Queue

- 먼저 들어간 자료가 먼저 나오는 자료구조 (선입선출)

- 자료를 넣는 Enquueu 함수와 자료를 빼는 Dequeue 함수

- 시간 복잡도

  - enqueue : O(1)
  - dequeue : O(N)

<br>

## Machine Learning

### 지도학습

Supervised Learning

정답(예측하고자 하는 대상 y의 데이터)이 있는 데이터셋을 학습

(ex. 게임이탈 원인 분석 : 요인(x) = 게임 시간, 게임 머니, 아이템 개수, 레벨 등
                                           결과(y) = 게임 이탈 or 유지

설명변수(정답에 영향을 미칠만한 요소 = 요인(x)) 와 종속변수(정답 = 결과(y)) 존재

정답에 영향을 미칠 것 같은 변수, 모델을 인간이 직접 선택하므로 **인간 개입에 의한 분석**이라고 불림

**관측치끼리의 관계, 연관성을 통해 결과를 예측하려는 목적**

확률과 통계 기반의 모델

- ##### **회귀 분석**

  설명변수(X)를 토대로 종속변수(Y)를 예측 + 설명변수(X)와 종속변수(Y)의 정확한 인과관계 파악

  - **Y가** **연속형인 경우** 사용 (ex. 키의 유전 유무, 집값 변동 요소)

  - 통계적 가설의 의한 모델 -> 
    R-square(결정계수 80% 이상이면 데이터를 적절하게 설명)
    p-value(t-통계량 0.05보다 작으면 통계적으로 유의) 등 모델을 평가하는 통계량 제시 -> 
    해석이 필요

  - 회귀계수를 통한 X-Y의 인과관계 파악 가능

    Y = a1X1 + a2X2 + ... + anXn + b (n개의 설명변수) # 설명변수마다 y에 미치는 영향. 고유의 기울기 추정 

  - **다중공선성 발생 가능**

    (설명변수(x)들의 관계가 강해서, 설명변수(x)들 끼리 정보를 공유하면서 종속변수(y)가 제대로 해석되지 못 하는 현상)

- ##### **분류 분석**

  분류 기준으로 예측 

  - **Y가 범주형(**Factor**형)인 경우** 사용 (ex. 고객 이탈 or 유지, 상황 or 비상환)

  - 이미 분류된 각 집단들의 특징(~을 할 것인지, 안 할 것인지)을 알고 있으므로 정답(y)을 분류(예측)

  - 트리기반 모델을 제외하고는 대부분 black box 모델 -> 모델 내부를 확인할 수 없으므로 인과관계가 아닌 오직 예측에 집중

  - 비모수적 검정 모델 

    (통계적인 가설이 필요 없음, 통계적으로 모델을 평가하는 기준이 없으므로, 테스트 데이터, 검증용 데이터로 모델을 검증해야 함)

  - Model : 

    -   **K-NN**(K-Nearest Neighbors)
        유클리드 거리 계산식을 이용하여 가장 유사한 범주(그룹)를 가장 가까운 거리로 선택 (영화 추천, 종양 식별)
    -   **NB**(Naive Bayes)
        조건부 확률을 이용하여 예측 (spam 메일 분류, 주제별 문서 분류)
    -   **DT**(Decision Tree
        사용자가 매개변수를 설정하여 계층 구조 형태로 데이터를 나눔 (불순도가 낮을수록 좋은 트리)
    -   **RF**(Random Forest)
        여려 개의 결정 트리를 임의적으로 학습(앙상블 학습), 여러번의 학습으로 여러 트리를 생성하고 결합하여 최종 목표 변수를 예측
    -   **SVM**(Support Vector Machine)
        저차원, 고차원 데이터 등 다양한 데이터 셋에서 잘 동작, 결정 경계 사용 (얼굴, 문자, 숫자 인식)

### 비지도학습

UnSupervised Learning

정답이 없는 데이터셋을 학습, 지도학습과 다르게 종속변수(정답 = 결과(y))가 없음

특정한 정답이 없으므로 데이터에 대한 지식이 많이 필요, 주로 현업 업무

컴퓨터의 기계학습에 의한 분석

공통적인 데이터들끼리 묶어서 **패턴을 분석하려는 목적**

데이터를 세분화하거나 연관성 파악

- ##### 군집 분석

  - 집단을 세분화시키고, 집단에 따른 분류 (유클리드 거리 기반) - 최단거리법, 최장거리법, 메디안법, 중심법, 그룹평균법

  - 세분화된 집단에 대한 연구를 수행

  - 나뉘어진 집단들의 기준, 특징을 찾아가는 과정

  - 패턴을 추출하여 **그룹화를 통한 예측**(그룹 간 특성의 차이 발견)

  - Model

    - hierarchical(계층적 군집분석) : 가장 가까운 대상끼리 순차적으로 묶음
    - k-means(비계층군진화) : 군집의 수를 미리 알고 있는 경우, 군집의 중심은 사용자가 정함

  - ##### 연관성 분석

  - A를 하면 B도 하더라' 라는 연관성 발견. ex) 장바구니 분석(A를 사면 B도 사더라)

  - 상품 구매 규칙을 통한 구매 패턴 예측





 https://marasong.tistory.com/139 